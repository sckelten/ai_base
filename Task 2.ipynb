{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контентная рекомендательная система"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ты уже запрограммировал систему неперсональных рекомендаций, в этом занятии ты пройдешь все этапы разработки модели контентных рекомендаций, а значит перейдешь на следующий уровень кодинга. \n",
    "\n",
    "Какой у нас план?\n",
    "\n",
    " - Добавим необходимые библиотеки и загрузим датасеты «movies_metadata_fixed.csv», «credits.csv», «keywords.csv», «links_small.csv». \n",
    " - Соберем в один датасет необходимые данные, добавим поля с актерами фильмов и ключевыми словами.\n",
    " - Обработаем данные, чтобы они были представлены в удобном виде и удалим ненужные элементы. Переведем описание фильмов в текстовый формат (в колонках представим набор слов).\n",
    " - Чтобы появилась возможность сравнивать описания фильмов, превратим текст в вектор. \n",
    " - Найдем и сравним похожие фильмы по их **векторному представлению**. \n",
    "\n",
    " Поехали!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начни с импорта библиотек, подгружаем **Pandas** и **Ast** (с пакетом Literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируй библиотеки, которые мы использовали для решения первого задания\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз ты работаешь не только с таблицами, но и с текстами, а также с математическими объектами. Импортируем подходящие библиотеки и пакеты: **Scikit-learn** (пакеты CountVectorizer и cosine_similarity), **NLTK** (пакет SnowballStemmer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет из файла **«movies_metadata_fixed.csv»**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "\n",
       "     original_title                                           overview  ...  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...  ...   \n",
       "\n",
       "   release_date    revenue runtime  \\\n",
       "0    1995-10-30  373554033    81.0   \n",
       "1    1995-12-15  262797249   104.0   \n",
       "2    1995-12-22          0   101.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline             title  video  \\\n",
       "0                                                NaN         Toy Story  False   \n",
       "1          Roll the dice and unleash the excitement!           Jumanji  False   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  Grumpier Old Men  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          7.7       5415  \n",
       "1          6.9       2413  \n",
       "2          6.5         92  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузи файл movies_metadata_fixed.csv в переменную dataset\n",
    "dataset = pd.read_csv('./the-movies-dataset/movies_metadata_fixed.csv')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично первому занятию подготовь колонки **Жанры** и **Год выпуска фильма**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Animation, Comedy, Family]\n",
       "1    [Adventure, Fantasy, Family]\n",
       "2               [Romance, Comedy]\n",
       "3        [Comedy, Drama, Romance]\n",
       "4                        [Comedy]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обработай жанры в датасете\n",
    "literal_eval(dataset['genres'].iloc[0])\n",
    "[i['name'] for i in literal_eval(dataset['genres'].iloc[0])]\n",
    "dataset['genres'] = dataset['genres'].fillna('[]')\\\n",
    "                                     .apply(literal_eval)\\\n",
    "                                     .apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "dataset['genres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отдели год выпуска фильма от полной даты выхода\n",
    "dataset['year'] = pd.to_datetime(dataset.release_date).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме информации о фильмах нам нужны будут дополнительные данные, их мы загрузим из других файлов.\n",
    "\n",
    "В файле **credits.csv** хранится информация о съемочной группе, а база **keywords.csv** содержит информацию о ключевых словах-  это слова-теги, которые характеризуют каждый из фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('./the-movies-dataset/credits.csv')\n",
    "keywords = pd.read_csv('./the-movies-dataset/keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы прикрепить колонки с нужной информацией к рабочему датасету с фильмами из последних файлов, воспользуемся функцией **merge** из пакета **Pandas**. Объединяем колонки по столбцу \"id\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46628, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.merge(dataset, credits, on='id')\n",
    "dataset = pd.merge(dataset, keywords, on='id')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы ускорить вычисления и быстро создать прототип рекомендательной системы, создатели датасета подготовили выборку из 9219 фильмов **links_small.csv**. На этом наборе данных ты быстрее протестируешь идеи, а уже потом сможешь применить ко всей базе фильмов целиком. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_small = pd.read_csv('./the-movies-dataset/links_small.csv')\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9219, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd = dataset[dataset['id'].isin(links_small)]\n",
    "smd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видишь, наш датасет заметно уменьшился, можем переходить к обработке данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "\n",
    "Перед тобой стоит задача сравнить фильмы между собой, чтобы подобрать наиболее похожие. Как ты будешь определять эту \"похожесть\"? \n",
    "\n",
    "Есть пара идей:\n",
    " - Фильмы мог снять один и тот же режиссер\n",
    " - В фильмах сыграли одни и те же актеры\n",
    " - Наконец, сюжеты фильмов совпадают или один фильм продолжает другой\n",
    " \n",
    "Приведем в пример трилогию \"Хоббит\". Три части киноистории снял одним и тот же режиссер, актерский состав почти полностью совпадает, да и сюжет второй и третьей частей продолжают первую.\n",
    "\n",
    "Как раз эту информацию ты и попроббуешь собрать из нескольких колонок, а затем превратить в текст. Сейчас мы используем только эти поля из базы данных для примера, но есть и другие параметры, по которым фильмы могут совпадать (по смыслу). Ты можешь самостоятельно поработать с ними, когда завершишь общую часть второго задания.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начни с переменной **cast**. Этот формат ты уже использовал в первом задании, поэтому знаешь, как с ним справиться. Сначала примени функцию **literal_eval**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'cast_id': 14, 'character': 'Woody (voice)',...\n",
       "1    [{'cast_id': 1, 'character': 'Alan Parrish', '...\n",
       "2    [{'cast_id': 2, 'character': 'Max Goldman', 'c...\n",
       "3    [{'cast_id': 1, 'character': 'Savannah 'Vannah...\n",
       "4    [{'cast_id': 1, 'character': 'George Banks', '...\n",
       "Name: cast, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['cast'] = smd['cast'].apply(literal_eval)\n",
    "smd.cast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе **literal_eval** получаем список словарей в виде объектов языка Python. Информация, которая нам нужна, лежит в полях **name**. Сформируй список актерского состава тем же способом, что и в первом задании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...\n",
       "1    [Robin Williams, Jonathan Hyde, Kirsten Dunst,...\n",
       "2    [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...\n",
       "3    [Whitney Houston, Angela Bassett, Loretta Devi...\n",
       "4    [Steve Martin, Diane Keaton, Martin Short, Kim...\n",
       "Name: cast, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сформируй список актерского состава, используя лямбда-функцию\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd.cast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Теперь для каждого фильма у тебя есть список актеров. Теперь это поле мы превратим в одну большую строку. Предлагаем учитывать только главные роли фильма, оставим первые пять имен актеров, а остальные опустим.\n",
    "\n",
    "Чтобы отличать актеров с одинаковыми именами, но разными фамилиями, переведи строку в нижний регистр и убери пробелы в именах. Имя **Tom Hanks** запишется как **tomhanks**, тоже самое произойдет и с другими. Проделав эту операцию, алгоритм уже не будет считать фильмы похожими, просто потому что у актеров одинаковые имена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tomhanks timallen donrickles jimvarney wallace...\n",
       "1    robinwilliams jonathanhyde kirstendunst bradle...\n",
       "2    waltermatthau jacklemmon ann-margret sophialor...\n",
       "3    whitneyhouston angelabassett lorettadevine lel...\n",
       "4    stevemartin dianekeaton martinshort kimberlywi...\n",
       "Name: cast_str, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#оставь только пять первых актеров\n",
    "smd['cast'] = smd['cast'].apply(lambda cast: cast[:5] if len(cast) >= 5 else cast)\n",
    "\n",
    "#переведи в нижний регистр имена и удали пробелы между именем и фамилией\n",
    "smd['cast'] = smd['cast'].apply(lambda cast: [str.lower(actor.replace(\" \", \"\")) for actor in cast])\n",
    "\n",
    "#объедини актеров каждого фильма в одну строку, разделяя имена пробелами\n",
    "smd['cast_str'] = smd['cast'].apply(lambda cast: ' '.join(cast))\n",
    "smd.cast_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На очереди колонка **crew**. В ней хранится важная информация, а именно в поле **job** — здесь есть имена и должности всех людей, которые принимали участие в съемках фильма. Давай используем функцию **literal_eval** и рассмотрим поле в деталях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'credit_id': '52fe4284c3a36847f8024f49', 'de...\n",
       "1    [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...\n",
       "2    [{'credit_id': '52fe466a9251416c75077a89', 'de...\n",
       "3    [{'credit_id': '52fe44779251416c91011acb', 'de...\n",
       "4    [{'credit_id': '52fe44959251416c75039ed7', 'de...\n",
       "Name: crew, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#используй функцию literal_eval\n",
    "smd['crew'] = smd['crew'].apply(literal_eval)\n",
    "smd.crew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'credit_id': '52fe4284c3a36847f8024f49',\n",
       " 'department': 'Directing',\n",
       " 'gender': 2,\n",
       " 'id': 7879,\n",
       " 'job': 'Director',\n",
       " 'name': 'John Lasseter',\n",
       " 'profile_path': '/7EdqiNbr4FRjIhKHyPPdFfEEEFG.jpg'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['crew'].iloc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имя режиссера ты найдешь в поле **Director** (важно! это поле может отсутствовать). Напиши такую функцию, чтобы извлечь имя режиссера для каждого фильма, а если информации нет, то функция возвращает значение **np.nan**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      johnlasseter\n",
       "1       joejohnston\n",
       "2      howarddeutch\n",
       "3    forestwhitaker\n",
       "4      charlesshyer\n",
       "Name: director, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_director(crew):\n",
    "    for member in crew:\n",
    "        #проверьте, что должность - режиссер:\n",
    "        if member['job'] == 'Director':\n",
    "            #верните ответом имя режиссера\n",
    "            return member['name']\n",
    "    return np.nan\n",
    "smd['director'] = smd['crew'].apply(get_director)\n",
    "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "smd.director.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последняя колонка, которая тебе нужна - это **keywords**, те самые ключевые слова-теги. Давай посмотрим, как она выглядит. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 931, 'name': 'jealousy'},\n",
       " {'id': 4290, 'name': 'toy'},\n",
       " {'id': 5202, 'name': 'boy'},\n",
       " {'id': 6054, 'name': 'friendship'},\n",
       " {'id': 9713, 'name': 'friends'},\n",
       " {'id': 9823, 'name': 'rivalry'},\n",
       " {'id': 165503, 'name': 'boy next door'},\n",
       " {'id': 170722, 'name': 'new toy'},\n",
       " {'id': 187065, 'name': 'toy comes to life'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['keywords'].head().apply(literal_eval).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы извлечь данные, обратимся к полю **name** в каждом элементе списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [jealousy, toy, boy, friendship, friends, riva...\n",
       "1    [board game, disappearance, based on children'...\n",
       "2    [fishing, best friend, duringcreditsstinger, o...\n",
       "3    [based on novel, interracial relationship, sin...\n",
       "4    [baby, midlife crisis, confidence, aging, daug...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['keywords'] = smd['keywords'].apply(literal_eval)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd.keywords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ты хочешь рекомендовать похожие фильмы, а значит есть смысл, оставить только те ключевые слова, которые встречаются у нескольких фильмов. Исключим ключевые слова, которые встречаются лишь раз во всем датасете:\n",
    "- соберем все ключевые слова всех фильмов в один большой список\n",
    "- посчитаем, сколько раз встречалось каждое ключевое слово\n",
    "- удалим те ключевые слова, которые встретились только раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = smd.apply(lambda x: pd.Series(x['keywords']),axis=1)\\\n",
    "       .stack()\\\n",
    "       .reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "s = s.value_counts()\n",
    "s = s[s > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [jealousy, toy, boy, friendship, friends, riva...\n",
       "1    [board game, disappearance, based on children'...\n",
       "2         [fishing, best friend, duringcreditsstinger]\n",
       "3    [based on novel, interracial relationship, sin...\n",
       "4    [baby, midlife crisis, confidence, aging, daug...\n",
       "Name: keywords, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words\n",
    "smd['keywords'] = smd['keywords'].apply(filter_keywords)\n",
    "smd.keywords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ты собрал список слов-тегов для каждого фильма, но это еще не всё. Если вчитаться в список, то некоторые ключевые слова повторяются, хотя имеют разные формы (например, единственное и множественное число)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 88)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['friend'], s['friends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['boy'], s['boys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представь, в фильме есть ключевые слова **friend и boy**, а в другом **friends и boys**. Алгоритм будет считать эти фильмы непохожими, а значит мы потеряем информацию.\n",
    "\n",
    "Чтобы разобраться с этой проблемой, используй специальный алгоритм - **стеммер** (stemmer) от англ. слова **stem** - корень.  \n",
    "Этот алгоритм поможет тебе выделить корень слова и превратить всех **friends** во **friend**, а **boys** в **boy**.\n",
    "\n",
    "Посмотри, как это работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dog', 'friend', 'boy')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "stemmer.stem('dogs'), stemmer.stem('friends'), stemmer.stem('boys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм сработал, как нужно: для твоей задачи вполне подходит. Давай обработаем каждое ключевое слово для каждого фильма этим алгоритмом. Это улучшит результат поиска похожих фильмов (скоро сам в этом убедишься). \n",
    "\n",
    "Удобнее всего такое преобразование выразить как отдельную функцию. Напиши функцию, чтобы на входе она принимала список слов, а на выходе возращала уже обработанный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_keywords(x):\n",
    "    stemmed_tokens = []\n",
    "    for token in x:\n",
    "        try:\n",
    "            new_token = stemmer.stem(token)\n",
    "            stemmed_tokens.append(new_token)\n",
    "        except:\n",
    "            stemmed_tokens.append(token)\n",
    "    return stemmed_tokens\n",
    "\n",
    "#примените написанную выше функцию ко всему столбцу\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: stem_keywords(x))\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i.replace(\" \", \"\").lower() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jealousi toy boy friendship friend rivalri boy...\n",
       "1    boardgam disappear basedonchildren'sbook newho...\n",
       "2                   fish bestfriend duringcreditssting\n",
       "3    basedonnovel interracialrelationship singlemot...\n",
       "4    babi midlifecrisi confid age daughter motherda...\n",
       "Name: keywords_str, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['keywords_str'] = smd['keywords'].apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "smd.keywords_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вау! Видим, что ты добрался практически до финиша разработки контентной системы рекомендаций. Все колонки, что ты так кропотливо готовил, пора направить в дело: keywords, director, cast, genres.\n",
    "\n",
    "Нужно объединить эти колонки в одну большую строку для каждого фильма, так у каждого объекта будет подробное текстовое описание. Объединяй колонки через пробел (чтобы слова не слиплись) и переводи все в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_fields(data):\n",
    "    concat = data['keywords'] + data['cast'] + [data['director']] + data['genres']\n",
    "    result = ' '.join([str(i).lower() for i in concat])\n",
    "    return result\n",
    "smd['soup'] = smd.apply(lambda x: concat_fields(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Toy Story',\n",
       " 'jealousi toy boy friendship friend rivalri boynextdoor newtoy toycomestolif tomhanks timallen donrickles jimvarney wallaceshawn johnlasseter animation comedy family')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['title'].iloc[0], smd['soup'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрати внимание, как выглядит запись о  фильме \"История игрушек\". В строке есть информация и об актерах, и о режиссере, и о жанре фильма, и про ключевые слова не забыли. Если для человека эта строка абсолютно бесполезная, то компьютер с ней быстро справится.\n",
    "\n",
    "___\n",
    "\n",
    "Помнишь в задании мы рассмотрели векторное представление текста, чтобы рекомендации заработали? Начинаем работу по преобразованию данных. Сейчас мы превратим этот текст в математический объект - **вектор**. Как ты знаешь, вектор это направленный отрезок. Это довольно простой объект, но для нас он будет ключевым элементом в системе контентных рекомендаций. \n",
    "\n",
    "Когда мы переведем описание каждого фильма в вектор, то как и с любыми другими векторами, ты, наконец, сможешь автоматически сравнивать фильмы между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы преобразовать текстовое описание в вектор нам будет нужен объект **CountVectorizer**. Он умеет превращать огромный массив текстов в набор векторов. Посмотри на пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brown</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumped</th>\n",
       "      <th>lazy</th>\n",
       "      <th>like</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brown  cat  dog  fox  jumped  lazy  like  over  quick\n",
       "Doc1      1    0    1    1       1     1     0     1      1\n",
       "Doc2      0    0    1    0       0     0     1     0      0\n",
       "Doc3      0    1    0    0       0     0     1     0      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(['quick brown fox jumped over lazy dog', \n",
    "                          'i like dog', \n",
    "                          'i like cat'])\n",
    "pd.DataFrame(data=vectors.toarray(), \n",
    "             index=['Doc1', 'Doc2', 'Doc3'],\n",
    "             columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На входе было 3 предложения:\n",
    "- 'quick brown fox jumped over lazy dog', \n",
    "- 'i like dog',\n",
    "- 'i like cat'\n",
    "\n",
    "На выходе мы получили 3 вектора. Обрати внимание, как эти вектора выглядят. Координаты вектора - это слова, поэтому, если в предложении было слово **dog**, то в координате под названием **dog** будет число 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно так же, чуть позже, ты превратишь все описания фильмов в вектора. Но есть ещё один вопрос, как сравнивать эти вектора?\n",
    "\n",
    "Простой вопрос, какое предложение больше похоже на **quick brown fox jumped over lazy dog**: \n",
    "    - i like dog\n",
    "    - i like cat\n",
    "Правильный ответ - i like dog. В исходном предложении есть слово dog, но нет слова cat.\n",
    "\n",
    "Чтобы это понять математически, используют скалярное произведение векторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.26726124, 0.        ],\n",
       "       [0.26726124, 1.        , 0.5       ],\n",
       "       [0.        , 0.5       , 1.        ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция **cosine_similarity** вычислит скалярное произведение между всеми парами векторов. В примере у нас 3 вектора - 3 предложения, поэтому на выходе функции мы получим табличку размера **3x3**.  \n",
    "В первой строке таблицы записаны значения скалярных произведений между первым предложением и остальными двумя. Легко заметить, что расстояние вектора до самого себя = 1 (т.к. предложение на 100% совпадает с самим собой), расстояние до второго предложения = 0.26, до третьего = 0. То есть благодаря рассчитаным значениям мы сделаем вывод, что второе предложение гораздо ближе к первому, чем третье.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давай провернём этот трюк с нашими фильмами Создай объект **CountVectorizer** и передай в функцию **fit_transform** все текстовые описания фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9219, 21384)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "count_matrix = count.fit_transform(smd['soup'])\n",
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ты получил матрицу размером **9219x21346** - это значит, что все **9219** фильмов превратились в векторы размером **21346** элементов. \n",
    "\n",
    "Заметь, что объект CountVectorizer дает возможность установить дополнительные настройки\n",
    " - параметр **ngram_range=(1,2)** помогает учитывать не только отдельные слова, но и пары слов\n",
    " - параметр **min_df=2** отфильтрует все слова, которые встречались меньше чем в двух фильмах\n",
    " \n",
    "Что нам даёт информация о размере матрицы? В нашем датасете **21346** уникальных слов и пар слов, которые встречались не менее чем в двух фильмах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось вычислить скалярные произведения между всеми парами фильмов. Повтори все то же, что и в примере выше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9219, 9219)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В уменьшенном датасете было **9219** фильмов, поэтому матрица предсказаний имеет размеры **9219x9219**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция рекомендации фильма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ты уже сделал большую работу, теперь всё готово для написания функции рекомендации фильма. Тебе нужно написать функцию, которая принимает на вход фильм, а в ответ советует другие, похожие на него. Фильмы с самым минимальным расстоянием до фильма на входе в итоге и попадут в список рекомендаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd = smd.reset_index()\n",
    "# Сохрани в переменную title колонку с названиями фильмов из датасета smd\n",
    "titles = smd.title\n",
    "indices = pd.Series(smd.index, index=smd['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ура, все готово! Проверим твою систему в работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899    The Lord of the Rings: The Fellowship of the Ring\n",
       "8833            The Hobbit: The Battle of the Five Armies\n",
       "4436                The Lord of the Rings: The Two Towers\n",
       "8537                  The Hobbit: The Desolation of Smaug\n",
       "5074        The Lord of the Rings: The Return of the King\n",
       "1693                                The Lord of the Rings\n",
       "8867                                             Warcraft\n",
       "477                                            The Shadow\n",
       "5852                                           The Hobbit\n",
       "2730                      Baby: Secret of the Lost Legend\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Hobbit: An Unexpected Journey').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотри, самые похожие фильмы на кино \"The Hobbit: An Unexpected Journey\" тоже будут фильмами про хоббитов. Система использует описания фильмов, чтобы выдавать рекомендации — ты отлично справился со вторым заданием. Остается сделать последний шаг в финальном проекте, разработать систему коллаборативной фильтрации. Об этом мы поговорим в третьем задании. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522                Terminator 2: Judgment Day\n",
       "4739       Terminator 3: Rise of the Machines\n",
       "8854                       Terminator Genisys\n",
       "974                                    Aliens\n",
       "5924                                 Fortress\n",
       "7296                     Terminator Salvation\n",
       "6394                             District B13\n",
       "6967                                 Doomsday\n",
       "2412                                  RoboCop\n",
       "5296                                   Zardoz\n",
       "5638    Sky Captain and the World of Tomorrow\n",
       "7403                                    Gamer\n",
       "7502                          The Book of Eli\n",
       "8042                         The Darkest Hour\n",
       "4742    The League of Extraordinary Gentlemen\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Terminator').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
